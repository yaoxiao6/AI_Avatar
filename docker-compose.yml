# AI_Avatar/docker-compose.yml

version: '3.8'

services:
  ollama-server:
    build:
      context: ./ollama-server
      dockerfile: dockerfile
    image: ai-avatar/ollama-server:latest
    ports:
      - "11434:11434"  # Default Ollama port
    networks:
      - ai-network
    volumes:
      - ollama-data:/root/.ollama  # Persist Ollama models
    
  # flask-rag service has been removed
      
  node-backend:
    build:
      context: ./node-backend
      dockerfile: dockerfile
    image: ai-avatar/node-backend:latest
    ports:
      - "4000:4000" # Not true on GCP Cloud Run
    networks:
      - ai-network
    environment:
      - OLLAMA_SERVER_ADDRESS=http://ollama-server:11434
      - FIREBASE_PROJECT_ID=ai-avatar-451519
    depends_on:
      - ollama-server

networks:
  ai-network:
    driver: bridge

volumes:
  ollama-data: